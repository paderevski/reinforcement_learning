{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358b8dbe-bf5f-4afb-9de1-d01cd41bb93f",
   "metadata": {},
   "source": [
    "# Monte Carlo Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fcb04a-f562-46ae-a56a-910fd8f3a560",
   "metadata": {},
   "source": [
    "First-visit monte carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4cd6c07-7bb7-4540-97f1-7648a40c3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib, random, pandas, seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40b7fa8b-430e-409d-ade5-a33e2db45d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Environment:\n",
    "    states: list\n",
    "    actions: list\n",
    "    step: callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "579a0679-c8e8-4bce-a5b8-a0cb54136c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tape:\n",
    "    def __init__(self, policy:  callable, environment: Environment, length: int):\n",
    "        self.environment = environment\n",
    "        self.policy = policy\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = [-1]\n",
    "        self.length = length\n",
    "        \n",
    "    def playout(self, start_state):\n",
    "        first_seen = dict()\n",
    "        self.states = [start_state]\n",
    "        self.actions = [self.policy[start_state]]\n",
    "        self.rewards = [-1]\n",
    "        s = self.states[0]\n",
    "        a = self.actions[0]\n",
    "        for i in range(1, self.length + 1): # the last s and a are ignored\n",
    "            print(s,a)\n",
    "            if s not in first_seen:\n",
    "                first_seen.update( {s : i-1} )\n",
    "            r,s = self.environment.step(s,a)\n",
    "            if s is None:\n",
    "                break\n",
    "            self.rewards.append(r)\n",
    "            self.states.append(s)\n",
    "            a = self.policy[s]\n",
    "            self.actions.append(a)\n",
    "        self.first_seen = first_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "046d315e-3307-45c2-a6b3-6403ad43a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class monte_carlo:\n",
    "    def __init__(self, policy, environment, num_steps):\n",
    "        self.num_steps = num_steps\n",
    "        self.V = dict()\n",
    "        self.V_count = dict()\n",
    "        self.pi = dict()\n",
    "        self.policy = policy\n",
    "        self.environment= environment\n",
    "\n",
    "    def estimate_v_first_visit(self, start_state):\n",
    "        V = { s : random.random() for s in self.environment.states }\n",
    "        V_counts = { s : 0 for s in self.environment.states }\n",
    "\n",
    "        loop_counter = 0\n",
    "        while True:\n",
    "            loop_counter += 1\n",
    "            if loop_counter > 5:\n",
    "                break\n",
    "            tape = tape(self.policy, self.environment, self.num_steps)\n",
    "            tape.playout(start_state)\n",
    "            G = 0\n",
    "            for t in range(self.num_steps-1,-1,-1):\n",
    "                G = gamma*G + tape.rewards[t+1]\n",
    "                if tape.first_seen[t] == t:\n",
    "                    s = tape.states[t]\n",
    "                    n = V_counts[s]\n",
    "                    v = V[s]\n",
    "                    v = ((n * v) + G) /(n+1)\n",
    "                    V[s] = v\n",
    "                    V_counts[s] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cccba99c-33a1-4d01-86df-6ebc53e8818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gambler_states = list(range(101))\n",
    "gambler_actions = list(range(1,100))\n",
    "gambler_policy = dict()\n",
    "gambler_values = dict()\n",
    "\n",
    "with open(\"gambler-policy.txt\",\"r\") as f:\n",
    "    text = f.readlines()\n",
    "    for l in text:\n",
    "        l = l.strip()\n",
    "        i, x = l.split(\" \")\n",
    "        gambler_policy.update({int(i):int(round(float(x)))})\n",
    "\n",
    "with open(\"gambler-value.txt\",\"r\") as f:\n",
    "    text = f.readlines()\n",
    "    for l in text:\n",
    "        i, x = l.split(\" \")\n",
    "        gambler_values.update({i:x})\n",
    "\n",
    "def gambler_step(s,a):\n",
    "    if (s==0 or s==100):\n",
    "        return None, None\n",
    "    if (random.random() < 0.4):\n",
    "        s = s + a\n",
    "    else:\n",
    "        s = s - a\n",
    "    r = 1 if s == 100 else 0\n",
    "    if (s<0 or s>100):\n",
    "        raise ValueError(f\"Invalid state encountered: {s}, {a}\")\n",
    "    return r, s\n",
    "    \n",
    "gambler_environment = Environment(actions = gambler_actions, states = gambler_states, step=gambler_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5d7ee-667c-48c4-ad0e-43d740672bfc",
   "metadata": {},
   "source": [
    "Let's try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "13573159-b7a2-4424-a16f-836dad1f317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = tape(gambler_policy, gambler_environment, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "06dc4f4a-3648-4e25-8a83-d67a05108220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 5\n",
      "75 25\n",
      "50 50\n",
      "0 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[80, 75, 50, 0]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tp.playout(80)\n",
    "\n",
    "tp.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c540156b-3bca-44b3-b4b3-7ae1b6b9e350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 25, 50, 0]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "69ba7f85-5b9d-487a-934e-469df017d48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, 0, 0]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "37c73b30-28c3-45f9-81ed-5f4944bed90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = monte_carlo(gambler_policy, gambler_environment, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "8aa22ffc-5739-46a5-a38c-89793a98bd7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'tape' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[266], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_v_first_visit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[263], line 19\u001b[0m, in \u001b[0;36mmonte_carlo.estimate_v_first_visit\u001b[0;34m(self, start_state)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop_counter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m tape \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_steps)\n\u001b[1;32m     20\u001b[0m tape\u001b[38;5;241m.\u001b[39mplayout(start_state)\n\u001b[1;32m     21\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'tape' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "mc.estimate_v_first_visit(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385d6b6-7e28-463e-b41f-be0326497643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
